# Voiceflow API Key
VF_DM_API_KEY=your_voiceflow_api_key_here

# Port Configuration
UDP_PORT=6980  # Optional, defaults to 6980
TCP_PORT=12345 # Optional, defaults to 12345

# --- Transcription Provider Selection ---
# Set USE_GROQ to true to use Groq Cloud API (faster, requires GROQ_API_KEY).
# Set USE_GROQ to false (or omit) to use the local Whisper ASR Docker service.
USE_GROQ=false

# --- Groq Cloud API Settings (Only used if USE_GROQ=true) ---
GROQ_API_KEY=
# Optional Groq API URL (Defaults to transcription endpoint)
# GROQ_API_URL=https://api.groq.com/openai/v1/audio/transcriptions
# Optional Groq Model ID (Defaults to whisper-large-v3-turbo). Options:
# whisper-large-v3         (Best accuracy, multilingual, transcription+translation)
# whisper-large-v3-turbo   (Good speed/cost, multilingual, transcription only)
# distil-whisper-large-v3-en (Fastest/cheapest, English only, transcription only)
GROQ_MODEL=whisper-large-v3-turbo
# Optional: Specify input audio language (ISO-639-1 code like 'en', 'fr') to improve accuracy.
# Leave commented out for automatic language detection.
# GROQ_LANGUAGE=

# --- Local Whisper ASR Service Settings (Only used if USE_GROQ=false) ---
# Optional: URL of the local Whisper ASR webservice container
# WHISPER_SERVER_URL=http://whisper-asr:9000
# Optional: Whisper model to use by the local service (e.g., tiny, base, small, medium, large-v3, tiny.en, base.en, etc.)
WHISPER_MODEL=base
# Optional: Whisper engine for the local service (openai_whisper, faster_whisper, whisperx)
WHISPER_ENGINE=openai_whisper
# Optional: Device for the local service (cpu, cuda)
WHISPER_DEVICE=cpu
# Optional: Enable Voice Activity Detection filter in the local service (only works with faster_whisper engine)
# WHISPER_VAD_FILTER=false

# Response Settings
INCLUDE_TEXT_WITH_AUDIO=false  # Set to true to send text response with audio (for Core2)
